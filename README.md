# Data-Analyst-Agent
This project builds an autonomous multi-agent system for conversational data analysis using Llama 3 within a Medallion Architecture. It validates user queries, generates SQL/Python insights, and delivers visualizations, enabling safe, accurate, and accessible analytics for all users.

---------------------------------------01_Environment_Setup ---------------------------------------
This script is designed to set up the environment for a data-analysis workflow using Spark, Databricks, Hugging Face, and Unity Catalog.
It performs three major tasks:

1. Initialize a Spark Session

The script starts a Spark application called â€œLLMAgentDataAnalysisâ€, which will be used to process and transform data.

2. Define All Important Paths and Configurations

It specifies:

The input dataset location (a CSV file in Databricks Volumes).

The Bronze, Silver, and Gold table output paths for the Medallion architecture.

The Databricks connection details, such as host, warehouse ID, and SQL endpoint.

The Unity Catalog catalog and schema where tables will be stored.

This helps the rest of the pipeline know where data is coming from and where processed data should be saved.

3. Retrieve API Tokens Securely

The code tries to fetch two secret tokens from Databricks Secrets:

Hugging Face API token

Databricks API token

If the secrets are found, they are loaded securely into the environment.

If not, the script falls back to hard-coded tokens (with a warning).
This ensures the notebook still runsâ€”even though it's insecure for production.

4. Return All Configuration Values

At the end, the script uses:

dbutils.notebook.exit()


to return a JSON object containing all the important configurations and tokens.

This allows other notebooks or agents to use these values as input to continue the pipeline.

----------------------------------------------------------------------------------------------------


-----------------------02_Data_Pipeline_Medallion_Architecture ------------------------------

This notebook processes your retail dataset using the Medallion Architecture, which has three layers: Bronze, Silver, and Gold. Each layer improves the quality and structure of the data.

It uses the environment/settings provided by the previous notebook, 01_Environment_Setup.

1. Retrieve Environment Variables

The notebook first loads all the important configuration values passed from the previous setup notebook (paths, catalog, schema, API keys, etc.).
If the values cannot be retrieved, it sets fallback defaults so the notebook can still run.

Purpose:
Ensure every part of the pipeline uses the same consistent settings.

2. Bronze Layer â€“ Raw Ingestion

The notebook:

Reads the raw CSV file from a Unity Catalog Volume.

Cleans column names (spaces, symbols, uppercase â†’ standardized format).

Saves this unprocessed but standardized dataset as a Bronze Delta table.

Purpose:
Store the raw data in a stable, structured, and queryable format, but without modifying the actual values.

3. Silver Layer â€“ Cleaned & Standardized Data

From the Bronze table, the notebook:

Converts the invoice date into a proper timestamp.

Calculates the total amount for each transaction.

Removes cancelled invoices (based on invoice IDs starting with â€œCâ€).

Renames columns to consistent names.

Fixes missing customer IDs by replacing null values with a placeholder.

It then saves this transformed dataset as a Silver Delta table.

Purpose:
Clean and standardize the data so it becomes reliable and ready for analytics.

4. Gold Layer â€“ Business KPIs

From the Silver table, the notebook computes:

Monthly sales (yearâ€“month).

Total quantity sold.

Total sales amount.

Number of transactions.

It groups these metrics by month, country, product code, and description, and stores them in the Gold Delta table.

Purpose:
Produce a business-ready dataset containing key performance indicators that can be used for dashboards, reporting, or insights.

5. Completion Signal

At the end, the notebook sends a success message so that any workflow or orchestration tool knows the pipeline ran successfully.

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------

------------------------------03_Multi_Agent_System_Definition-----------------------------------


This notebook defines and initializes a multi-agent system for data analysis using LLM (Llama 3) and Databricks SQL.
It mainly sets up two agents â€”
(1) an Input Validator Agent that filters valid user queries, and
(2) a Data Analyst Agent that performs Text-to-SQL and creates visualizations.
Finally, it returns all configurations as JSON for use in the orchestrator notebook.â€

ğŸ§© Block 1: Imports and Environment Setup

â€œIn the first part, we import all required libraries â€” like Spark, LangChain, HuggingFaceHub, pandas, matplotlib, and Databricks SQL connector.
Then, we make sure that the Databricks SQL connector is installed and start a Spark session if not already running.
Logging is also configured so that we can track each process step and error clearly.â€

ğŸ—£ Key point to mention:

â€œThis part ensures that the entire environment is ready for LLM + SQL + visualization work.â€

âš™ï¸ Block 2: Retrieve Configuration Variables

â€œThis block retrieves global variables that were passed from the previous notebook, such as API tokens, Databricks host, warehouse ID, catalog, and schema.
It uses dbutils.widgets to read a JSON string and then extracts and validates the required variables.â€

ğŸ—£ If asked why validation is needed:

â€œWe check that all critical parameters are not empty â€” because missing tokens or URLs would break our database connection.â€

ğŸ§  If run locally, fallback values are provided using environment variables for development only.

ğŸ¤– Block 3: Initialize the Large Language Model

â€œHere, we initialize the LLM â€” Meta-Llama-3-8B-Instruct â€” from Hugging Face Hub.
The temperature is kept low (0.1) for more factual, deterministic answers, and we limit the maximum tokens to 512 for efficiency.â€

ğŸ—£ Key point:

â€œThis is the main brain that both agents will use for understanding and reasoning.â€

ğŸ§  Block 4: Input Validator Agent

â€œThis is the first agent. It uses a simple LLMChain with a prompt that checks if the userâ€™s query is valid or invalid.
A query is valid only if it asks something related to sales, products, or transactions â€” otherwise, itâ€™s rejected.â€

ğŸ—£ Example to say:

â€œFor example, if someone says â€˜Show me monthly sales by country,â€™ itâ€™s VALID.
But if they say â€˜Hi, how are you?â€™ or something malicious, itâ€™s INVALID.â€

âœ… Purpose: Protects the system from irrelevant or risky inputs.

ğŸ§± Block 5: Databricks SQL Connection

â€œThis block connects the system to the Databricks SQL warehouse.
We extract the hostname from the Databricks URL and then use SQLDatabase.from_databricks() to connect using catalog, schema, and tokens.â€

ğŸ—£ Explain simply:

â€œThis connection allows the agent to query real data stored in Databricks using SQL.â€

ğŸ“Š Block 6: Python Visualization Tool

â€œThis is a custom LangChain tool that takes the SQL query output and creates a visualization.
It tries to read the data as CSV, and if that fails, it tries a space-separated format using regex.â€

ğŸ—£ Explain logic:

â€œOnce the data is parsed into a DataFrame, it decides which chart to make automatically:

Line chart for monthly sales

Bar chart for top countries or products

Scatter plot or generic bar chart for other cases.
It then encodes the chart as a Base64 image and returns it as HTML so it can be displayed directly.â€

âœ… Purpose: Converts raw query results into readable visual insights automatically.

ğŸ§° Block 7: SQL Toolkit and Memory Setup

â€œHere, we combine the LLM with the SQLDatabase using LangChainâ€™s SQLDatabaseToolkit.
We add our visualization tool to it, and also use ConversationBufferMemory â€” so the agent remembers context between user queries.â€

ğŸ—£ Say:

â€œThis memory helps in follow-up questions like â€˜now show me only the top 5.â€™â€

ğŸ§® Block 8: Create the Data Analyst Agent

â€œNow we create the main Data Analyst Agent using create_sql_agent().
This agent uses the LLM, the SQL toolkit, and our custom visualization tool.
It can automatically convert a natural language question into an SQL query, execute it on Databricks, and visualize the result.â€

ğŸ—£ In short:

â€œThis is the heart of the system â€” it performs text-to-SQL and visual analysis autonomously.â€

ğŸ§¾ Block 9: Return JSON Configuration

â€œFinally, the notebook doesnâ€™t return Python objects directly â€” because Databricks notebooks canâ€™t pass complex objects using dbutils.notebook.run().
Instead, we prepare a JSON payload with all model and database configuration details.
Then we exit using dbutils.notebook.exit() so the next notebook can rebuild the agents.â€

ğŸ—£ Summarize:

â€œThis makes our system modular â€” setup and orchestration are separate, which is good for scalability.â€

ğŸ§  Final Summary to Say at End

â€œSo overall, this notebook sets up two agents â€”
one for validation and another for analysis and visualization â€” both powered by Llama 3 and Databricks SQL.
It ensures clean environment setup, secure variable handling, intelligent visualization, and easy integration with the orchestrator notebook."

"""
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------

------------------------------04_Main_Orchestrator_and_Testing----------------------------------------


This notebook is the main orchestrator for running the multi-agent data analysis system.
It re-initializes both agents from prior notebooks, exposes a single run function to process queries end-to-end, and includes test cases to demonstrate validation, SQL answering, and visualization.

ğŸ§© Block 1: Re-Initialization (Configs â†’ Agents)
â€œFirst, we call 01_Environment_Setup to fetch fresh config (tokens, hosts, warehouse info).
Then we call 03_Multi_Agent_System_Definition, which returns a JSON payload with all rebuild parameters.
Using this, we re-create:
â€¢ the LLM (Llama-3 via HuggingFace)
â€¢ the Input Validator Agent (VALID/INVALID gatekeeper)
â€¢ the Databricks SQL connection (catalog, schema, warehouse)
â€¢ the custom visualization tool
â€¢ the SQL toolkit + memory
â€¢ and the Data Analyst Agent (Text-to-SQL + tool-calling).â€
ğŸ—£ Key point to mention:
â€œThis notebook doesnâ€™t redefine logicâ€”it rebuilds the exact agents from configuration, ensuring reproducibility and clean separation of concerns.â€
âš™ï¸ Block 2: Orchestrator Function (run_multi_agent_system)
â€œThis function accepts a user query and runs the full pipeline:


Sends the query to the Validator Agent.


If the result is VALID, invokes the Data Analyst Agent which executes SQL and (when appropriate) produces a visualization.


Uses Databricks display to show rich outputs.
If the query is INVALID, it returns a polite scope message.â€


ğŸ—£ Why this design?:
â€œBy centralizing validation and analysis in one call, the orchestrator delivers a consistent, controlled entry point for all queries.â€
ğŸ§ª Block 3: Test Cases (Demo Suite)
â€œThis section runs a variety of queries to showcase behavior:
â€¢ Valid numeric aggregation: â€˜total sales for 2011â€™
â€¢ Valid categorical top-N: â€˜top 5 most sold productsâ€™
â€¢ Country breakdown: â€˜sales amount per countryâ€™
â€¢ Explicit visualization requests
â€¢ Monthly trend plotting
â€¢ Schema discovery (tables and schemas)
â€¢ Off-topic / greetings to show rejections by the validator.â€
ğŸ—£ Key point:
â€œThese tests prove the entire flowâ€”validate â†’ analyze â†’ visualize/displayâ€”and demonstrate both happy paths and guardrails.â€

ğŸ§  If someone asks â€œwhat actually changes here vs the definition notebook?â€
â€œ03_* defines the agents and returns a JSON contract; 04_* rebuilds those agents from that contract and runs them with real queries.â€
ğŸ—£ Example to say (for the function):
â€œIf a user asks, â€˜Show me the total sales amount for each country, and visualize it,â€™ the orchestrator verifies itâ€™s a valid retail query, then the analyst agent generates SQL, fetches results from Databricks, and triggers the visualization tool to return a plot embedded as HTML.â€

âœ… Final Summary to Say at End
â€œOverall, this orchestrator notebook reconstructs the agents from configuration, exposes a clean run function for end-to-end processing, and demonstrates the system through comprehensive test cases. It ensures modular architecture (definition vs execution), repeatability, and a clear user pathway from query validation to SQL analysis and visualization.â€


